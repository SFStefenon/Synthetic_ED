{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJRksKzmCU6IZ6nOum9qUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SFStefenon/synthetic_ED/blob/main/diffusion_m2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66004d4hL3iJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim, autograd\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as T\n",
        "from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D, Trainer1D, Dataset1D\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device:', device)\n",
        "\n",
        "model = Unet1D(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels = 32\n",
        ")\n",
        "\n",
        "diffusion = GaussianDiffusion1D(\n",
        "    model,\n",
        "    seq_length = 32,\n",
        "    timesteps = 5000,\n",
        "    objective = 'pred_v'\n",
        ")\n",
        "\n",
        "storage = './saved_results/'\n",
        "\n",
        "img_size = 32\n",
        "batchsize = 16\n",
        "train_data_path = '32by32_rfi_train_perfect_labels_1.csv'\n",
        "size = '32by32'\n",
        "\n",
        "for classes in range(0,133):\n",
        "    print(f'Running: {classes}')\n",
        "    try:\n",
        "        if any(pd.read_csv(train_data_path).label.values==int(classes)): # Check if the class exists\n",
        "            considered_label = int(classes)\n",
        "            class_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'D0', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'AD', 'AU', 'C00', 'C01', 'C02', 'C03', 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', 'C31', 'C32', 'C33', 'C34', 'C35', 'C36', 'C37', 'C38', 'C39', 'C40', 'C41', 'C42', 'C43', 'C44', 'C45', 'C46', 'C47', 'C48', 'C49', 'C50', 'C51', 'C52', 'C53', 'C54', 'C55', 'C56']\n",
        "            class_list = class_list[considered_label]\n",
        "\n",
        "            class RFI(Dataset):\n",
        "                def __init__(self, path, img_size, c_label=considered_label, transform=None):\n",
        "                    self.transform = transform\n",
        "                    rfi_df = pd.read_csv(path)\n",
        "                    ########################################################################\n",
        "                    images = rfi_df.iloc[:, 1:].values.astype('uint8').reshape(-1, img_size, img_size)\n",
        "                    self.images = images[np.where(rfi_df.label.values==c_label)]\n",
        "                    self.labels = rfi_df.label.values[np.where(rfi_df.label.values==c_label)]\n",
        "                    ########################################################################\n",
        "                    print('Image size:', self.images.shape)\n",
        "                    print('--- Label ---')\n",
        "                    print(rfi_df.label.value_counts())\n",
        "                def __len__(self):\n",
        "                    return len(self.images)\n",
        "                def __getitem__(self, idx):\n",
        "                    label = self.labels[idx]\n",
        "                    img = self.images[idx]\n",
        "                    img = Image.fromarray(self.images[idx])\n",
        "                    if self.transform:\n",
        "                        img = self.transform(img)\n",
        "                    return img, label\n",
        "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "            dataset = RFI(train_data_path, img_size, considered_label, transform=transform)\n",
        "            dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
        "\n",
        "            for data, labels in dataloader:\n",
        "                fig, ax = plt.subplots(figsize=(12,8))\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "                ax.imshow(make_grid(data, nrow=16).permute(1,2,0))\n",
        "                figure_name = str(storage) + 'Results_DIF_class_' + str(classes) + '_'+size+'_image_original.pdf'\n",
        "                plt.savefig(figure_name)\n",
        "                break\n",
        "\n",
        "            training_seq = data.reshape(batchsize, img_size, img_size)\n",
        "            dataset = Dataset1D(training_seq)\n",
        "            loss = diffusion(training_seq)\n",
        "            loss.backward()\n",
        "\n",
        "            trainer = Trainer1D(\n",
        "                diffusion,\n",
        "                dataset = dataset,\n",
        "                train_batch_size = 32,\n",
        "                train_lr = 8e-5,\n",
        "                train_num_steps = 5000,           # total training steps\n",
        "                gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "                ema_decay = 0.995,                # exponential moving average decay\n",
        "                amp = True,                       # turn on mixed precision\n",
        "            )\n",
        "\n",
        "            trainer.train()\n",
        "\n",
        "            images = diffusion.sample(batch_size = batchsize).cpu()\n",
        "            print(images.shape)\n",
        "            name = str(storage) + 'Results_DIF_class_' + str(classes) + '_' + size + 'sampled_seq.pt'\n",
        "            torch.save(images, name)\n",
        "\n",
        "    except Exception as e:\n",
        "       # By this way we can know about the type of error occurring\n",
        "        print(\"The error is: \", e)\n",
        "        pass\n",
        "\n",
        "print('Finished')"
      ]
    }
  ]
}
